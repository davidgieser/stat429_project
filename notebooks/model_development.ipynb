{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicting Funding Rate Direction: Model Development**\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "In this notebook, we aim to develop predictive models to forecast the **direction of the funding rate movement** for Bitcoin perpetual futures contracts on Binance. The funding rate is a crucial metric in futures trading, reflecting the cost of holding positions and influencing traders' strategies. Accurately predicting its direction can provide significant advantages in trading decisions.\n",
    "\n",
    "Our objectives are:\n",
    "\n",
    "- **Data Preprocessing and Feature Engineering**: Clean and prepare the data, extract meaningful features, and handle any data-related challenges.\n",
    "- **Model Training and Evaluation**: Train various machine learning models to predict the funding rate direction and evaluate their performance.\n",
    "- **Model Improvement and Selection**: Enhance model performance through techniques like hyperparameter tuning and select the best-performing model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# absolute path of the project's root directory\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# project root directory to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# import modules\n",
    "from utilities import (\n",
    "    load_data,\n",
    "    preprocess_data,\n",
    "    create_features,\n",
    "    train_classification_model,\n",
    "    save_model\n",
    ")\n",
    "\n",
    "from utilities.functions import (\n",
    "    add_lag_features,\n",
    "    add_technical_indicators,\n",
    "    apply_smote,\n",
    "    perform_hyperparameter_tuning,\n",
    "    evaluate_classification_model,\n",
    "    plot_feature_importance\n",
    ")\n",
    "\n",
    "from config import (\n",
    "    BINANCE_BTC_PERP_CSV,\n",
    "    MODEL1_PATH,\n",
    "    SCALER1_PATH,\n",
    "    RANDOM_STATE\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1: Data Preprocessing and Feature Engineering**\n",
    "\n",
    "In this step, we prepare the data for modeling by performing preprocessing tasks and creating new features that may improve model performance.\n",
    "\n",
    "### **1.1 Determining Funding Rate Direction**\n",
    "\n",
    "We create the target variable `direction` to indicate whether the funding rate is expected to **increase (`1`)** or **decrease/remain the same (`0`)** in the next time period.\n",
    "\n",
    "- **Methodology**:\n",
    "  - Shift the `funding_rate` column by one period to get the future funding rate.\n",
    "  - Compare the future funding rate with the current funding rate to determine the direction.\n",
    "  - The `direction` is set to `1` if the future funding rate is higher; otherwise, it's `0`.\n",
    "\n",
    "### **1.2 Feature Engineering**\n",
    "\n",
    "To enhance the model's predictive power, we generate additional features:\n",
    "\n",
    "- **Lag Features**:\n",
    "  - `funding_rate_lag1`: Funding rate from the previous period.\n",
    "  - `open_interest_lag1`: Open interest from the previous period.\n",
    "  - `mark_price_lag1`: Mark price from the previous period.\n",
    "\n",
    "- **Technical Indicators**:\n",
    "  - `funding_rate_ma3`: 3-period moving average of the funding rate.\n",
    "\n",
    "- **Cyclical Time Features**:\n",
    "  - Convert time-based features (hour, day, month) into cyclical features using sine and cosine transformations to capture periodic patterns.\n",
    "\n",
    "- **Data Handling**:\n",
    "  - **Missing Values**: Filled `NaN` values resulting from lagging and moving averages using backward fill (`bfill`).\n",
    "  - **Scaling**: Standardized numerical features to ensure they're on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "df = load_data(BINANCE_BTC_PERP_CSV)\n",
    "df = preprocess_data(df)\n",
    "df = create_features(df)\n",
    "\n",
    "# Create the 'direction' target variable\n",
    "df['future_funding_rate'] = df['funding_rate'].shift(-1)\n",
    "df['direction'] = (df['future_funding_rate'] > df['funding_rate']).astype(int)\n",
    "df.drop(columns=['future_funding_rate'], inplace=True)\n",
    "\n",
    "# Add lag features\n",
    "df = add_lag_features(df)\n",
    "\n",
    "# Add technical indicators\n",
    "df = add_technical_indicators(df)\n",
    "\n",
    "# Handle NaNs appropriately\n",
    "df.bfill(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2: Model Training and Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1 Random Forest Classifier**\n",
    "\n",
    "#### **Description**\n",
    "\n",
    "Random Forest is an ensemble learning method that operates by constructing multiple decision trees during training and outputting the mode of the classes as the prediction.\n",
    "\n",
    "#### **Implementation**\n",
    "\n",
    "- **Handling Class Imbalance**: Used **SMOTE (Synthetic Minority Over-sampling Technique)** to balance the classes in the training data.\n",
    "- **Hyperparameter Tuning**: Employed `GridSearchCV` to find the optimal hyperparameters, such as the number of estimators and maximum depth.\n",
    "- **Training**: Trained the Random Forest model with the best-found hyperparameters.\n",
    "\n",
    "#### **Evaluation**\n",
    "\n",
    "- **Metrics Used**: Same as logistic regression for consistency.\n",
    "- **Results**:\n",
    "  - Observed improvements in predictive performance over logistic regression.\n",
    "  - Evaluated the model's ability to predict the minority class accurately.\n",
    "  - Plotted feature importance to understand which features contributed most to the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceed only if df is not empty\n",
    "if not df.empty:\n",
    "    # Define features and target\n",
    "    feature_columns = [\n",
    "        'funding_rate_lag1', 'funding_rate_lag2',\n",
    "        'funding_rate_ma3', 'funding_rate_ma5',\n",
    "        'open_interest', 'open_interest_lag1',\n",
    "        'mark_price', 'mark_price_lag1',\n",
    "        'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'month_sin', 'month_cos'\n",
    "    ]\n",
    "    X = df[feature_columns]\n",
    "    y = df['direction']\n",
    "\n",
    "    # Split the data\n",
    "    split_index = int(0.8 * len(X))\n",
    "    X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
    "    y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "\n",
    "    if not X_train.empty and not X_test.empty:\n",
    "        # Scale numerical features\n",
    "        numeric_features = [\n",
    "            'funding_rate_lag1', 'funding_rate_lag2',\n",
    "            'funding_rate_ma3', 'funding_rate_ma5',\n",
    "            'open_interest', 'open_interest_lag1',\n",
    "            'mark_price', 'mark_price_lag1'\n",
    "        ]\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train[numeric_features])\n",
    "        X_test_scaled = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "        # Convert scaled features back to DataFrame\n",
    "        X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=numeric_features, index=X_train.index)\n",
    "        X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=numeric_features, index=X_test.index)\n",
    "\n",
    "        # Combine scaled numerical features with cyclical features\n",
    "        cyclical_features = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'month_sin', 'month_cos']\n",
    "        X_train_prepared = pd.concat(\n",
    "            [X_train_scaled_df.reset_index(drop=True), X_train[cyclical_features].reset_index(drop=True)],\n",
    "            axis=1\n",
    "        )\n",
    "        X_test_prepared = pd.concat(\n",
    "            [X_test_scaled_df.reset_index(drop=True), X_test[cyclical_features].reset_index(drop=True)],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Apply SMOTE to balance class distribution\n",
    "        X_train_resampled, y_train_resampled = apply_smote(X_train_prepared, y_train.reset_index(drop=True))\n",
    "\n",
    "        # Initialize and train the Random Forest model\n",
    "        rf_model = RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced')\n",
    "        rf_model = train_classification_model(rf_model, X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Evaluate the initial model\n",
    "        print(\"\\nInitial Model Evaluation:\")\n",
    "        evaluate_classification_model(rf_model, X_test_prepared, y_test)\n",
    "\n",
    "        # Perform hyperparameter tuning\n",
    "        best_rf_model = perform_hyperparameter_tuning(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Evaluate the best model\n",
    "        print(\"\\nBest Model Evaluation After Hyperparameter Tuning:\")\n",
    "        evaluate_classification_model(best_rf_model, X_test_prepared, y_test)\n",
    "\n",
    "        # Adjust classification threshold if necessary (e.g., threshold=0.5)\n",
    "        y_proba = best_rf_model.predict_proba(X_test_prepared)[:, 1]\n",
    "        custom_threshold = 0.5\n",
    "        print(f\"\\nEvaluation with Custom Threshold ({custom_threshold}):\")\n",
    "        evaluate_classification_model(best_rf_model, X_test_prepared, y_test, y_proba, threshold=custom_threshold)\n",
    "\n",
    "        # Plot feature importance\n",
    "        plot_feature_importance(best_rf_model, X_train_prepared.columns)\n",
    "\n",
    "        # Save the trained model and scaler\n",
    "        save_model(best_rf_model, MODEL1_PATH)\n",
    "        save_model(scaler, SCALER1_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Logistic Regression**\n",
    "\n",
    "#### **Description**\n",
    "\n",
    "Logistic Regression is a linear model commonly used for binary classification problems. It models the probability that a given input belongs to a particular category.\n",
    "\n",
    "#### **Implementation**\n",
    "\n",
    "- **Handling Class Imbalance**: Addressed through techniques like class weighting or resampling (if applicable).\n",
    "- **Feature Scaling**: Applied `StandardScaler` to numerical features to normalize the data.\n",
    "- **Training**: Trained the logistic regression model using the processed training data.\n",
    "\n",
    "#### **Evaluation**\n",
    "\n",
    "- **Metrics Used**:\n",
    "  - **Accuracy**: Overall correctness of the model.\n",
    "  - **Precision**: Correct positive predictions out of all positive predictions.\n",
    "  - **Recall**: Correct positive predictions out of all actual positives.\n",
    "  - **ROC AUC Score**: Measure of the model's ability to distinguish between classes.\n",
    "\n",
    "- **Results**:\n",
    "  - Presented the classification report and confusion matrix.\n",
    "  - Analyzed the model's performance, particularly on the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3 Model Comparison**\n",
    "\n",
    "- Compared the performance of logistic regression and Random Forest models.\n",
    "- Discussed which model performed better and why.\n",
    "- Considered factors like overfitting, computational efficiency, and interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
